{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from groundupml.neuralnetwork.activations import ReLuLayer, SoftmaxCrossEntropyLayer, \\\n",
    "    SoftmaxLayer\n",
    "from groundupml.neuralnetwork.neural_network2 import LinearLayer\n",
    "from groundupml.utils.data_manipulation import split_data, scale_min_max\n",
    "from groundupml.utils.functions import one_hot_to_class, to_one_hot\n",
    "from groundupml.utils.data_tools import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (120, 4) (120, 3)\n",
      "Test shapes: (30, 4) (30, 3)\n",
      "LinearLayer(n_nodes=3, n_inputs=4, learning_rate=0.01)\n",
      "LinearLayer(n_nodes=3, n_inputs=3, learning_rate=0.01)\n",
      "Epoch: 0 Cost: 1.1002218586089867\n",
      "Epoch: 1000 Cost: 0.4821150035933241\n",
      "Epoch: 2000 Cost: 0.3471549880771153\n",
      "Epoch: 3000 Cost: 0.26215004207740755\n",
      "Epoch: 4000 Cost: 0.20207265869246954\n",
      "Epoch: 5000 Cost: 0.1607525187660711\n",
      "Epoch: 6000 Cost: 0.13222562403426535\n",
      "Epoch: 7000 Cost: 0.11199447414135827\n",
      "Epoch: 8000 Cost: 0.09718253555735516\n",
      "Epoch: 9000 Cost: 0.08602606785365294\n",
      "[0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 2 1 2 0 0 2 1 2 1 2 2 2 2 0]\n",
      "[0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 2 2 1 2 0]\n",
      "[[10.  0.  0.]\n",
      " [ 0. 11.  2.]\n",
      " [ 0.  0.  7.]]\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, proportion=0.8)\n",
    "\n",
    "# Scale features to be between 0 and 1 for NN\n",
    "X_train = scale_min_max(X_train)\n",
    "X_test = scale_min_max(X_test)\n",
    "\n",
    "# Convert labels to one hot vectors\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n",
    "\n",
    "print('Train shapes:', X_train.shape, y_train.shape)\n",
    "print('Test shapes:', X_test.shape, y_test.shape)\n",
    "\n",
    "# Train neural network\n",
    "n_epochs = 10000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "fc_layer1 = LinearLayer(n_nodes=3, n_inputs=4, learning_rate=learning_rate)\n",
    "fc_layer1.init_weights()\n",
    "print(fc_layer1)\n",
    "fc_layer2 = LinearLayer(n_nodes=3, n_inputs=3, learning_rate=learning_rate)\n",
    "fc_layer2.init_weights()\n",
    "print(fc_layer2)\n",
    "sm_layer = SoftmaxCrossEntropyLayer()\n",
    "\n",
    "costs = []\n",
    "for i in range(n_epochs):\n",
    "    # Forward propogate\n",
    "    z1 = fc_layer1.forward_propogate(X_train)\n",
    "    #print('z1:', z1.shape)\n",
    "    z2 = fc_layer2.forward_propogate(z1)\n",
    "    #print('z2:', z2.shape)\n",
    "    #print('z2:', z2[:5])\n",
    "    activations = sm_layer.forward_propogate(z2)\n",
    "    #print('activations.shape:', activations.shape)\n",
    "    #print('activations:', activations[:5])\n",
    "\n",
    "    # Calculate costs using squared error\n",
    "    #loss = 0.5 * np.sum((y_train - activations)**2)\n",
    "    loss = sm_layer.calculate_loss(y_train)\n",
    "    costs.append(loss)\n",
    "\n",
    "    # Backward propogate error gradients\n",
    "    gradients_a = sm_layer.back_propogate(y_train)\n",
    "    #d_error = activations - y_train\n",
    "    #print('d_error:', d_error)\n",
    "    #gradients_a = sm_layer.back_propogate(d_error)\n",
    "    #print('Gradients a:', gradients_a)\n",
    "    #print('gradients_a.shape:', gradients_a.shape)\n",
    "    gradients_z2 = fc_layer2.back_propogate(gradients_a)\n",
    "    #print('Weights shape:',fc_layer2.weights.shape)\n",
    "    #print('d_weights shape:', fc_layer2.d_weights.shape)\n",
    "    fc_layer2.update_weights()\n",
    "    #print('gradients_z2.shape:', gradients_z2.shape)\n",
    "    gradients_z1 = fc_layer1.back_propogate(gradients_z2)\n",
    "    fc_layer1.update_weights()\n",
    "    #print('gradients_z1.shape:', gradients_z1.shape)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch:', i, 'Cost:', costs[-1])\n",
    "\n",
    "# Get test predictions\n",
    "z1 = fc_layer1.forward_propogate(X_test)\n",
    "z2 = fc_layer2.forward_propogate(z1)\n",
    "a = sm_layer.forward_propogate(z2)\n",
    "predictions = np.argmax(a, axis=1)\n",
    "actual = one_hot_to_class(y_test)\n",
    "\n",
    "print(predictions)\n",
    "print(actual)\n",
    "\n",
    "print(confusion_matrix(actual, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gupml-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
